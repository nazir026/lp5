{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P9tCRhd-_mHj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6BgcbEw_pmi",
        "outputId": "1635e7a7-45a5-4aae-90a1-4ddaf8515cc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJAj3P6a_zvi",
        "outputId": "4d96a0a2-ed79-490f-9b1c-b706a6fe5453"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp310-cp310-linux_x86_64.whl size=3365648 sha256=730e91d335e92a2ceec2c878e7d6f55de6ad5d3f4b99794c95d47a4e5f5bc380\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/b5/97ec4cfccdde26e0f3590ad6e09a5242d508dff09704ef86c1\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()"
      ],
      "metadata": {
        "id": "fiGLcMpn_thf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, x_train, y_train, rank, size):\n",
        "# Split the data across the nodes\n",
        "  n = len(x_train)\n",
        "  chunk_size = n // size\n",
        "  start = rank * chunk_size \n",
        "  end = (rank + 1) * chunk_size\n",
        "  if rank == size - 1:\n",
        "      end = n\n",
        "  x_train_chunk = x_train[start:end]\n",
        "  y_train_chunk = y_train[start:end]\n",
        "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  #Train the model\n",
        "  model.fit(x_train_chunk, y_train_chunk, epochs=1, batch_size=32)\n",
        "  # Compute the accuracy on the training data\n",
        "  train_loss, train_acc = model.evaluate(x_train_chunk, y_train_chunk, verbose=2)\n",
        "  # Reduce the accuracy across all nodes\n",
        "  train_acc = comm.allreduce(train_acc, op=MPI.SUM)\n",
        "  return train_acc / size\n"
      ],
      "metadata": {
        "id": "nVULhuzQ_v0F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "# Train the model\n",
        "   train_acc = train(model, x_train, y_train, rank, size)\n",
        "# Compute the accuracy on the test data\n",
        "   test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "# Reduce the accuracy across all nodes\n",
        "   test_acc = comm.allreduce(test_acc, op=MPI.SUM)\n",
        "# Print the results if rank == 0\n",
        "   print(f\"Epoch {epoch + 1}: Train accuracy = {train_acc:.4f}, Test accuracy = {test_acc /size:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm3Dcniq_-7O",
        "outputId": "c22915e0-e857-4dce-80b8-5e78185cbeed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2069 - accuracy: 0.9413\n",
            "1875/1875 - 13s - loss: 0.0854 - accuracy: 0.9764 - 13s/epoch - 7ms/step\n",
            "313/313 - 2s - loss: 0.0820 - accuracy: 0.9762 - 2s/epoch - 5ms/step\n",
            "Epoch 1: Train accuracy = 0.9764, Test accuracy = 0.9762\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0747 - accuracy: 0.9787\n",
            "1875/1875 - 11s - loss: 0.0532 - accuracy: 0.9851 - 11s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0579 - accuracy: 0.9805 - 2s/epoch - 5ms/step\n",
            "Epoch 2: Train accuracy = 0.9851, Test accuracy = 0.9805\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0580 - accuracy: 0.9828\n",
            "1875/1875 - 10s - loss: 0.0403 - accuracy: 0.9891 - 10s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0519 - accuracy: 0.9829 - 2s/epoch - 8ms/step\n",
            "Epoch 3: Train accuracy = 0.9891, Test accuracy = 0.9829\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0468 - accuracy: 0.9859\n",
            "1875/1875 - 11s - loss: 0.0372 - accuracy: 0.9893 - 11s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0539 - accuracy: 0.9828 - 2s/epoch - 6ms/step\n",
            "Epoch 4: Train accuracy = 0.9893, Test accuracy = 0.9828\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0396 - accuracy: 0.9882\n",
            "1875/1875 - 10s - loss: 0.0296 - accuracy: 0.9918 - 10s/epoch - 5ms/step\n",
            "313/313 - 3s - loss: 0.0522 - accuracy: 0.9841 - 3s/epoch - 9ms/step\n",
            "Epoch 5: Train accuracy = 0.9918, Test accuracy = 0.9841\n"
          ]
        }
      ]
    }
  ]
}